{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split,ParameterGrid\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder,OneHotEncoder\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import(\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    StackingClassifier\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score,ConfusionMatrixDisplay,roc_auc_score,RocCurveDisplay,precision_score\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTENC\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import os\n",
    "import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_in_feature(dataset,target):\n",
    "    \"\"\"\n",
    "    Split dataset between features and target\n",
    "    \"\"\"\n",
    "    y=dataset[target]\n",
    "    X=dataset.drop(target,axis=1)\n",
    "\n",
    "    return X,y\n",
    "\n",
    "def split_dataset(X,y):\n",
    "    \"\"\"\n",
    "    Split dataset in three:\n",
    "    Test, Train, Validation\n",
    "    \"\"\"\n",
    "    X_train,X_to_test,y_train,y_to_test=train_test_split(X,y,test_size=0.2,stratify=y,random_state=180)\n",
    "    X_to_fit,X_to_val,y_to_fit,y_to_val=train_test_split(X_train,y_train,test_size=0.5,stratify=y_train,random_state=180)\n",
    "    \n",
    "    return X_to_test,X_to_fit,X_to_val,y_to_test,y_to_fit,y_to_val\n",
    "\n",
    "def preprocessing_features(X_to_fit):\n",
    "    \"\"\"\n",
    "    Depending of feature type its receive a type of preprocessor\n",
    "    \"\"\"\n",
    "    categorical_columns = X_to_fit.select_dtypes(include=['object']).columns.to_list()\n",
    "    numerical_columns = ['age']\n",
    "\n",
    "\n",
    "\n",
    "    num_pipeline= Pipeline(\n",
    "                    steps=[\n",
    "                        ('imputer',SimpleImputer(strategy='median')),\n",
    "                        ('scaler',StandardScaler(with_mean=False))\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "    cat_pipeline=Pipeline(\n",
    "                    steps=[\n",
    "                        ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "                        ('one_hot_enconder',OneHotEncoder())                        \n",
    "                    ]\n",
    "                )\n",
    "\n",
    "    preprocessor=ColumnTransformer(\n",
    "                    [\n",
    "                        ('num_pipeline',num_pipeline,numerical_columns),\n",
    "                        ('cat_pipeline',cat_pipeline,categorical_columns)\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "    preprocessor.fit(X_to_fit)\n",
    "    return preprocessor\n",
    "\n",
    "def preprocessing_target(y_to_fit):\n",
    "    \"\"\"\n",
    "    Label Enconder target variables\n",
    "    \"\"\"\n",
    "    y_labels=LabelEncoder().fit(y_to_fit)\n",
    "    print(y_labels.classes_)\n",
    "    return y_labels\n",
    "\n",
    "def mlflow_tracking_training(experimental_name,X_test,X_fit,X_val,y_test,y_fit,y_val):\n",
    "    \"\"\"\n",
    "    Tracking and save mlflow model\n",
    "    \"\"\"\n",
    "    caminho_pasta=f'{experimental_name}_{datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")}'\n",
    "    os.makedirs(caminho_pasta, exist_ok=True)\n",
    "    os.environ[\"MLFLOW_ARTIFACT_ROOT\"] = caminho_pasta\n",
    "    print(caminho_pasta)\n",
    "    mlflow.set_experiment(experimental_name)\n",
    "    \n",
    "    for i in range(len(list(models))):\n",
    "        model=list(models.values())[i]\n",
    "        model_name=list(models.keys())[i]\n",
    "            \n",
    "        print(f'--------------------Trainning {model_name} Model-------------------------------')\n",
    "        model_params = params.get(model_name, {})\n",
    "        param_grid = list(ParameterGrid(model_params))\n",
    "        loop=0\n",
    "        for params_combination in param_grid:\n",
    "            loop +=1\n",
    "            try:\n",
    "                with mlflow.start_run():\n",
    "                    mlflow.log_param(\"model\", model_name)\n",
    "                    mlflow.log_params(params_combination)\n",
    "                    model.set_params(**params_combination)                  \n",
    "                    model.fit(X_fit,y_fit)               \n",
    "                    train_acc=model.score(X_fit,y_fit)\n",
    "                    mlflow.sklearn.log_model(model,f\"{model_name}\")\n",
    "                    print(f'{model_name} Model Train Accuracy: {train_acc:.2f}')\n",
    "                    mlflow.log_metric(\"train_acc\", train_acc)\n",
    "\n",
    "                    print(f'--------------------Vailidating {model_name} Model-------------------------------')\n",
    "\n",
    "                    pred_val=model.predict(X_val)\n",
    "                    acc_score_validation =accuracy_score(y_val, pred_val)            \n",
    "                    mlflow.log_metric(\"Validation Accuracy Score\",acc_score_validation)\n",
    "                    print(f\"Validation Dataset Accuracy: {acc_score_validation:0.2f}\")\n",
    "\n",
    "                    report_validation = classification_report(y_val, pred_val, output_dict=True)\n",
    "                    df_report_validation = pd.DataFrame(report_validation).transpose()\n",
    "                \n",
    "\n",
    "                    artifact_path=os.path.join(caminho_pasta,f'report_validation_{loop}_{model_name}.csv')\n",
    "                    df_report_validation.to_csv(artifact_path)\n",
    "                    mlflow.log_artifact(artifact_path)\n",
    "\n",
    "                    auc_score_valid = roc_auc_score(y_val,pred_val)\n",
    "                    mlflow.log_metric(\"Validation AUC Score\",auc_score_valid)  \n",
    "\n",
    "                    \n",
    "                    display=RocCurveDisplay.from_predictions(y_val,pred_val)\n",
    "                    plt.title(\"Validation\")\n",
    "                    plt.show()\n",
    "                    artifact_path=os.path.join(caminho_pasta,f\"{model_name}_{loop}_validation_roc_curve.png\")\n",
    "                    display.plot()\n",
    "                    plt.savefig(artifact_path)\n",
    "                    mlflow.log_artifact(artifact_path)\n",
    "\n",
    "                    cm=confusion_matrix(y_val,pred_val,labels=model.classes_)\n",
    "                    \n",
    "                    disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=model.classes_)\n",
    "                    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "                    disp.plot(ax=ax, values_format='d', cmap='GnBu')\n",
    "                    ax.set_title(f'{model_name}: Validation')\n",
    "\n",
    "                    artifact_path=os.path.join(caminho_pasta,f\"{model_name}_{loop}_validation_conf_matrix.png\")\n",
    "                    plt.savefig(artifact_path)\n",
    "                    mlflow.log_artifact(artifact_path)\n",
    "\n",
    "                    mlflow.log_metric(f\"Validation Precision Score 0\",precision_score(y_val, pred_val, average='binary',pos_label=0))\n",
    "                    mlflow.log_metric(f\"Validation Precision Score 1\",precision_score(y_val, pred_val, average='binary',pos_label=1))\n",
    "\n",
    "                    \n",
    "                    print(f'--------------------Testing {model_name} Model-------------------------------')\n",
    "                    pred_test=model.predict(X_test)\n",
    "                    acc_score_test=accuracy_score(y_test, pred_test)            \n",
    "                    mlflow.log_metric(\"Testing Accuracy Score\",acc_score_test)\n",
    "                    print(f\"Test Dataset Accuracy: {acc_score_test:0.2f}\")\n",
    "\n",
    "                    report_testing = classification_report(y_test, pred_test, output_dict=True)\n",
    "                    df_report_testing = pd.DataFrame(report_testing).transpose()\n",
    "\n",
    "                    artifact_path=os.path.join(caminho_pasta,f'report_testing_{loop}_{model_name}.csv')        \n",
    "                    df_report_testing.to_csv(artifact_path)\n",
    "                    mlflow.log_artifact(artifact_path)\n",
    "\n",
    "                    cm=confusion_matrix(y_test,pred_test,labels=model.classes_)\n",
    "                    disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=model.classes_)\n",
    "                    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "                    disp.plot(ax=ax, values_format='d', cmap='BuPu')\n",
    "                    ax.set_title(f'{model_name}: Test')\n",
    "\n",
    "                    artifact_path=os.path.join(caminho_pasta,f\"{model_name}_{loop}_test_conf_matrix.png\")\n",
    "                    plt.savefig(artifact_path)\n",
    "                    mlflow.log_artifact(artifact_path)\n",
    "                    \n",
    "\n",
    "                    mlflow.log_metric(f\"Test Precision Score 0\",precision_score(y_test, pred_test, average='binary',pos_label=0))\n",
    "                    mlflow.log_metric(f\"Test Precision Score 1\",precision_score(y_test, pred_test, average='binary',pos_label=1))\n",
    "\n",
    "\n",
    "                    auc_score_test = roc_auc_score(y_test,pred_test)\n",
    "                    mlflow.log_metric(\"Test AUC Score\",auc_score_test)  \n",
    "\n",
    "                    \n",
    "                    display=RocCurveDisplay.from_predictions(y_test,pred_test)\n",
    "                    plt.title(\"Test\")\n",
    "                    display.plot()\n",
    "                    artifact_path=os.path.join(caminho_pasta,f\"{model_name}_{loop}_test_roc_curve.png\")\n",
    "                    plt.savefig(artifact_path)\n",
    "                    mlflow.log_artifact(artifact_path)\n",
    "                    log_print=f'Finish {model_name} with prameter: {params_combination}'\n",
    "                    print(log_print)\n",
    "                    mlflow.end_run() \n",
    "\n",
    "            except Exception as e:\n",
    "                    log_print=f'Error in{model_name} with prameter: {params_combination}: {str(e)}'\n",
    "                    print(log_print)\n",
    "\n",
    "                \n",
    "                                                      \n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "                \"Random_Forest\": RandomForestClassifier(random_state=42),\n",
    "                \"Decision_Tree\": DecisionTreeClassifier(random_state=42),\n",
    "                \"Gradient_Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "                \"Logistic_Regression\": LogisticRegression(random_state=42),\n",
    "                \"XGBClassifier\": XGBClassifier(),\n",
    "                \"AdaBoost_Classifier\": AdaBoostClassifier(random_state=42,),\n",
    "                \"SVM_Classifier\":svm.SVC(random_state=42,)\n",
    "            }\n",
    "params={\n",
    "                \"Decision_Tree\": {\n",
    "                    'criterion':['gini', 'log_loss', 'entropy'],\n",
    "                    #'max_features':['auto', 'sqrt', 'log2']\n",
    "                },\n",
    "                \"Random_Forest\":{                    \n",
    "                    #'n_estimators': [8,16,32,64,128,256],\n",
    "                    'criterion':['gini','entropy','log_loss'],\n",
    "                    #'max_features':['sqrt','log2']\n",
    "\n",
    "                },\n",
    "                \"Gradient_Boosting\":{\n",
    "                    'learning_rate':[.1,.01,.05,.001],\n",
    "                    #'subsample':[0.6,0.7,0.75,0.8,0.85,0.9],\n",
    "                    #'n_estimators': [8,16,32,64,128,256]\n",
    "                },\n",
    "               \"Logistic_Regression\":{},\n",
    "                \"XGBClassifier\":{\n",
    "                    'learning_rate':[.1,.01,.05,.001],\n",
    "                    #'n_estimators': [8,16,32,64,128,256]\n",
    "                },\n",
    "                \"CatBoosting_Classifier\":{\n",
    "                    'random_state':42,\n",
    "                    'depth': [6,8,10],\n",
    "                    'learning_rate': [0.01, 0.05, 0.1],\n",
    "                    'iterations': [30, 50, 100]\n",
    "                },\n",
    "                \"AdaBoost_Classifier\":{\n",
    "                    'learning_rate':[.1,.01,0.5,.001],\n",
    "                    'n_estimators': [8,16,32,64,128,256]\n",
    "                },\n",
    "                \"SVM_Classifier\":{\n",
    "                     'C':[1,2,5,10]\n",
    "                }\n",
    "                \n",
    "            }\n",
    "\n",
    "\n",
    "svm_linear=svm.LinearSVC(random_state=42)\n",
    "stacking_model = StackingClassifier(estimators=list(models.items()),final_estimator=svm_linear,cv=10,stack_method='auto')\n",
    "models[\"Stacking_Classifier\"] = stacking_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list(models))):\n",
    "        model_name=list(models.keys())[i]\n",
    "            \n",
    "        print(f'--------------------Trainning {model_name} Model-------------------------------')\n",
    "        model_params = params.get(model_name, {})\n",
    "        param_grid = list(ParameterGrid(model_params))\n",
    "        loop=0\n",
    "        for params_combination in param_grid:\n",
    "            model=list(models.values())[i]\n",
    "            model.set_params(**params_combination)                  \n",
    "            model.fit(X_fit,y_fit)               \n",
    "            train_acc=model.score(X_fit,y_fit)\n",
    "            print(f'{model_name} Model Train Accuracy: {train_acc:.2f}')\n",
    "\n",
    "            print(f'--------------------Vailidating {model_name} Model-------------------------------')\n",
    "            pred_val=model.predict(X_val)\n",
    "            acc_score_validation =accuracy_score(y_val, pred_val)            \n",
    "            print(f\"Validation Dataset Accuracy: {acc_score_validation:0.2f}\")\n",
    "            print(classification_report(y_val, pred_val))                         \n",
    "            auc_score_valid = roc_auc_score(y_val,pred_val)\n",
    "            print(\"Validation AUC Score\",auc_score_valid) \n",
    "\n",
    "                    \n",
    "            display=RocCurveDisplay.from_predictions(y_val,pred_val)\n",
    "            plt.title(\"Validation\")\n",
    "            plt.show()\n",
    "            display.plot()\n",
    "            cm=confusion_matrix(y_val,pred_val,labels=model.classes_)                    \n",
    "            disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=model.classes_)\n",
    "            fig, ax = plt.subplots(figsize=(8, 6))\n",
    "            disp.plot(ax=ax, values_format='d', cmap='GnBu')\n",
    "            ax.set_title(f'{model_name}: Validation')\n",
    "\n",
    "                \n",
    "\n",
    "            print(f\"Validation Precision Score 0\",precision_score(y_val, pred_val, average='binary',pos_label=0))\n",
    "            print(f\"Validation Precision Score 1\",precision_score(y_val, pred_val, average='binary',pos_label=1))\n",
    "\n",
    "                    \n",
    "            print(f'--------------------Testing {model_name} Model-------------------------------')\n",
    "            pred_test=model.predict(X_test)\n",
    "            acc_score_test=accuracy_score(y_test, pred_test)           \n",
    "                    \n",
    "            print(f\"Test Dataset Accuracy: {acc_score_test:0.2f}\")\n",
    "\n",
    "            print(classification_report(y_test, pred_test))\n",
    "                    \n",
    "\n",
    "                          \n",
    "                    \n",
    "\n",
    "            cm=confusion_matrix(y_test,pred_test,labels=model.classes_)\n",
    "            disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=model.classes_)\n",
    "            fig, ax = plt.subplots(figsize=(8, 6))\n",
    "            disp.plot(ax=ax, values_format='d', cmap='BuPu')\n",
    "            ax.set_title(f'{model_name}: Test')\n",
    "\n",
    "            \n",
    "\n",
    "            print(f\"Test Precision Score 0\",precision_score(y_test, pred_test, average='binary',pos_label=0))\n",
    "            print(f\"Test Precision Score 1\",precision_score(y_test, pred_test, average='binary',pos_label=1))\n",
    "\n",
    "\n",
    "            auc_score_test = roc_auc_score(y_test,pred_test)\n",
    "            print(\"Test AUC Score\",auc_score_test)  \n",
    "\n",
    "                    \n",
    "            display=RocCurveDisplay.from_predictions(y_test,pred_test)\n",
    "            plt.title(\"Test\")\n",
    "            display.plot()\n",
    "                    \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/cancer_data_cleaned.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=split_in_feature(df,'lung_cancer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_to_test,X_to_fit,X_to_val,y_to_test,y_to_fit,y_to_val = split_dataset(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=split_in_feature(df,'lung_cancer')\n",
    "X_to_test,X_to_fit,X_to_val,y_to_test,y_to_fit,y_to_val = split_dataset(X,y)\n",
    "y_labels=preprocessing_target(y_to_fit)\n",
    "y_test=y_labels.transform(y_to_test)\n",
    "y_fit=y_labels.transform(y_to_fit)\n",
    "y_val=y_labels.transform(y_to_val)\n",
    "y_fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor=preprocessing_features(X_to_fit)\n",
    "X_fit=preprocessor.transform(X_to_fit)\n",
    "X_test=preprocessor.transform(X_to_test)\n",
    "X_val=preprocessor.transform(X_to_val)\n",
    "\n",
    "y_labels=preprocessing_target(y_to_fit)\n",
    "y_test=y_labels.transform(y_to_test)\n",
    "y_fit=y_labels.transform(y_to_fit)\n",
    "y_val=y_labels.transform(y_to_val)\n",
    "y_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_tracking_training(\"Imbalance_Models\",X_test,X_fit,X_val,y_test,y_fit,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "ros = SMOTE(random_state=42)\n",
    "\n",
    "X_ros, y_ros = ros.fit_resample(X, y)\n",
    "\n",
    "X_to_test,X_to_fit,X_to_val,y_to_test,y_to_fit,y_to_val = split_dataset(X_ros,y_ros)\n",
    "preprocessor=preprocessing_features(X_to_fit)\n",
    "X_fit=preprocessor.transform(X_to_fit)\n",
    "X_test=preprocessor.transform(X_to_test)\n",
    "X_val=preprocessor.transform(X_to_val)\n",
    "\n",
    "y_labels=preprocessing_target(y_to_fit)\n",
    "y_test=y_labels.transform(y_to_test)\n",
    "y_fit=y_labels.transform(y_to_fit)\n",
    "y_val=y_labels.transform(y_to_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_ros),len(y_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_tracking_training(\"Balance_SMOTE_Models_with_parameters\",X_test,X_fit,X_val,y_test,y_fit,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance with SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "                \"Random_Forest\": RandomForestClassifier(random_state=42),\n",
    "                \"Decision_Tree\": DecisionTreeClassifier(random_state=42),\n",
    "                \"Gradient_Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "                \"Logistic_Regression\": LogisticRegression(random_state=42),\n",
    "                \"XGBClassifier\": XGBClassifier(),\n",
    "                \"AdaBoost_Classifier\": AdaBoostClassifier(random_state=42,),\n",
    "                \"SVM_Classifier\":svm.SVC(random_state=42,)\n",
    "            }\n",
    "params={\n",
    "                \"Decision_Tree\": {\n",
    "                    'criterion':['gini', 'log_loss', 'entropy'],\n",
    "                    'max_features':['auto', 'sqrt', 'log2'],\n",
    "                    'max_depth' : [3,5,10]\n",
    "\n",
    "                },\n",
    "                \"Random_Forest\":{                    \n",
    "                    'n_estimators': [8,16,32],\n",
    "                    'criterion':['gini','entropy','log_loss'],\n",
    "                    'max_depth' : [3,5,10],\n",
    "\n",
    "                },\n",
    "                \"Gradient_Boosting\":{\n",
    "                    'learning_rate':[.1,.01,.05,.001],\n",
    "                    'n_estimators': [8,16,32],\n",
    "                    'loss' : ['log_loss'],\n",
    "                    'max_depth' : [3,5,10],\n",
    "                },\n",
    "\n",
    "               \"Logistic_Regression\":{\n",
    "                   'penalty' : ['l1', 'l2', 'elasticnet', None],\n",
    "                    'C':[1,2,5],\n",
    "\n",
    "               },\n",
    "                \"XGBClassifier\":{\n",
    "                    'learning_rate':[.1,.01,.05,.001],\n",
    "                    'n_estimators': [8,16,32]\n",
    "                },\n",
    "                \"AdaBoost_Classifier\":{\n",
    "                    'learning_rate':[.1,.01,0.5,.001],\n",
    "                    'n_estimators': [8,16,32]\n",
    "                },\n",
    "                \"SVM_Classifier\":{\n",
    "                     'C':[1,2,5],\n",
    "                     'kernel' : ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed']\n",
    "                }\n",
    "                \n",
    "            }\n",
    "\n",
    "\n",
    "svm_linear=svm.LinearSVC(random_state=42)\n",
    "stacking_model = StackingClassifier(estimators=list(models.items()),final_estimator=svm_linear,cv=10,stack_method='auto')\n",
    "models[\"Stacking_Classifier\"] = stacking_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['gender', 'smoking', 'yellow_fingers',\n",
    "                                  'anxiety', 'peer_pressure', 'chronic_disease',\n",
    "                                  'fatigue', 'allergy', 'wheezing',\n",
    "                                  'alcohol_consuming', 'coughing',\n",
    "                                  'shortness_of_breath',\n",
    "                                  'swallowing_difficulty', 'chest_pain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/cancer_data_cleaned.csv',)\n",
    "\n",
    "\n",
    "X,y=split_in_feature(df,'lung_cancer')\n",
    "\n",
    "ros =SMOTENC(random_state=42,categorical_features=categorical_columns)\n",
    "\n",
    "X_to_test,X_to_fit,X_to_val,y_to_test,y_to_fit,y_to_val = split_dataset(X,y)\n",
    "\n",
    "X_ros, y_ros = ros.fit_resample(X_to_fit, y_to_fit)\n",
    "\n",
    "preprocessor=preprocessing_features(X_ros)\n",
    "X_fit=preprocessor.transform(X_ros)\n",
    "X_test=preprocessor.transform(X_to_test)\n",
    "X_val=preprocessor.transform(X_to_val)\n",
    "\n",
    "y_labels=preprocessing_target(y_ros)\n",
    "y_fit=y_labels.transform(y_ros)\n",
    "y_test=y_labels.transform(y_to_test)\n",
    "y_val=y_labels.transform(y_to_val)\n",
    "y_labels.inverse_transform([0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(preprocessor,open('../preprocessor.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_tracking_training(\"SMOTNC_Balance\",X_test,X_fit,X_val,y_test,y_fit,y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
